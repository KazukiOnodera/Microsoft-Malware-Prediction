#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Feb  2 21:42:32 2019

@author: Kazuki

Census_OSVersion を datetime とみなし、日毎の EngineVersion 等のシェアを計る

"""


import numpy as np
import pandas as pd
import os, gc
from glob import glob
from multiprocessing import cpu_count, Pool
import utils
utils.start(__file__)

PREF = 'f010'


features = ['EngineVersion', 'AppVersion', 'OsBuild', 'OsBuildLab',
            'IeVerIdentifier', 'Census_OSBranch', 'Census_OSBuildNumber',
            'Census_OSBuildRevision', 'AvSigVersion']


tr = pd.read_feather('../data/train.f')[['Census_OSVersion']+features]

te = pd.read_feather('../data/test.f')[['Census_OSVersion']+features]


# OS timestamp
datedictOS = np.load('../external/OSVersionTimestamps.npy')[()]
tr['Census_OSVersion_date'] = tr['Census_OSVersion'].map(datedictOS).dt.date
te['Census_OSVersion_date'] = te['Census_OSVersion'].map(datedictOS).dt.date

trte = pd.concat([tr, te], ignore_index=True)

gc.collect()

def multi(args):
    gc.collect()
    
    key, outpath_tr, outpath_te = args
    
    tbl = pd.crosstab(trte['Census_OSVersion_date'], 
                      trte[key], 
                      normalize='index')
    
    tbl = pd.melt(tbl.reset_index(), 'Census_OSVersion_date')
    tbl.columns = ['Census_OSVersion_date', key, f'CensusOSVersion_{key}_ratio']
    
    keys = ['Census_OSVersion_date', key]
    tr_f = pd.merge(tr[keys], tbl, on=keys, how='left')
    te_f = pd.merge(te[keys], tbl, on=keys, how='left')
    
    tr_f.drop(keys, axis=1, inplace=True)
    te_f.drop(keys, axis=1, inplace=True)
    
    # output
    tr_f.add_prefix(PREF+'_').to_feather(outpath_tr)
    te_f.add_prefix(PREF+'_').to_feather(outpath_te)
    
    return


os.system(f'rm ../data/tmp_*_{PREF}*')
argss = []
for i,c in enumerate(features):
    argss.append([c, f'../data/tmp_tr_{PREF}_{c}.f', f'../data/tmp_te_{PREF}_{c}.f'])

pool = Pool( cpu_count() )
pool.map(multi, argss)
pool.close()



# train
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_tr_{PREF}*'))], axis=1)
df.to_feather(f'../data/train_{PREF}.f')
del df; gc.collect()

# test
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_te_{PREF}*'))], axis=1)
df.to_feather(f'../data/test_{PREF}.f')

os.system(f'rm ../data/tmp_*_{PREF}*')







utils.end(__file__)

