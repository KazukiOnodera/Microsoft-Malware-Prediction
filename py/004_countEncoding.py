#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 24 17:41:39 2019

@author: kazuki.onodera

count category


"""

import numpy as np
import pandas as pd
import gc, os
from glob import glob

from multiprocessing import cpu_count, Pool
#from sklearn.preprocessing import LabelEncoder

import utils

PREF = 'f003'


col_cat = ['ProductName',
         'EngineVersion',
         'AppVersion',
         'AvSigVersion',
         'Platform',
         'Processor',
         'OsVer',
         'OsPlatformSubRelease',
         'OsBuildLab',
         'SkuEdition',
         'PuaMode',
         'SmartScreen',
         'Census_MDC2FormFactor',
         'Census_DeviceFamily',
         'Census_ProcessorClass',
         'Census_PrimaryDiskTypeName',
         'Census_ChassisTypeName',
         'Census_PowerPlatformRoleName',
         'Census_InternalBatteryType',
         'Census_OSVersion',
         'Census_OSArchitecture',
         'Census_OSBranch',
         'Census_OSEdition',
         'Census_OSSkuName',
         'Census_OSInstallTypeName',
         'Census_OSWUAutoUpdateOptionsName',
         'Census_GenuineStateName',
         'Census_ActivationChannel',
         'Census_FlightRing']

def frequency_encoding(variable, concat=False, dropna=True):
    """
    https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm
    """
    
    if concat:
        t = pd.concat([tr[variable], te[variable]]).value_counts(dropna=dropna).reset_index()
    else:
        t = tr[variable].value_counts(dropna=dropna).reset_index()
        
    t = t.reset_index()
    t.loc[t[variable] == 1, 'level_0'] = np.nan
    t.set_index('index', inplace=True)
    max_label = t['level_0'].max() + 1
    t.fillna(max_label, inplace=True)
    return t.to_dict()['level_0']

def multi(args):
    
    c, outpath_tr, outpath_te  = args
    
    tr_f = pd.DataFrame(index=tr.index)
    te_f = pd.DataFrame(index=te.index)
    
    # count train
    di = frequency_encoding(c, False, True)
    tr_f[c+'_tr'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_tr'] = te[c].map(lambda x: di.get(x, np.nan))
    
    # count train and na
    di = frequency_encoding(c, False, False)
    tr_f[c+'_tr_na'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_tr_na'] = te[c].map(lambda x: di.get(x, np.nan))
    
    utils.reduce_mem_usage(tr_f)
    utils.reduce_mem_usage(te_f)
    
    # output
    tr_f.add_prefix(PREF+'_').to_feather(outpath_tr)
    te_f.add_prefix(PREF+'_').to_feather(outpath_te)
    
    return

# =============================================================================
# main
# =============================================================================
if __name__ == "__main__":
    utils.start(__file__)
    
    tr = pd.read_feather('../data/train.f')[col_cat]
    te = pd.read_feather('../data/test.f')[col_cat]
    
    trte = pd.concat([tr, te], ignore_index=True)
    
    os.system(f'rm ../data/tmp_*_{PREF}*')
    argss = []
    for i,c in enumerate(col_cat):
        argss.append([c, f'../data/tmp_tr_{PREF}_{c}.f', f'../data/tmp_te_{PREF}_{c}.f'])
    
    pool = Pool( cpu_count() )
    pool.map(multi, argss)
    pool.close()
    
    del tr, te, trte; gc.collect()
    
    # train
    df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_tr_{PREF}*'))], axis=1)
    df.to_feather(f'../data/train_{PREF}.f')
    del df; gc.collect()
    
    # test
    df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_te_{PREF}*'))], axis=1)
    df.to_feather(f'../data/test_{PREF}.f')
    
    os.system(f'rm ../data/tmp_*_{PREF}*')
    
    utils.end(__file__)
