#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Feb  2 22:32:08 2019

@author: Kazuki

AvSigVersion を datetime とみなし、week毎の EngineVersion 等のシェアを計る

"""


import numpy as np
import pandas as pd
import os, gc
from glob import glob
from multiprocessing import cpu_count, Pool
from datetime import datetime
import utils
utils.start(__file__)

PREF = 'f012'


features = ['EngineVersion', 'AppVersion', 'OsBuild',
            'IeVerIdentifier', 'Census_OSBranch', 'Census_OSBuildNumber',
            'Census_OSBuildRevision']


tr = pd.read_feather('../data/train.f')[['AvSigVersion']+features]

te = pd.read_feather('../data/test.f')[['AvSigVersion']+features]


# AS timestamp
datedictAS = np.load('../external/AvSigVersionTimestamps.npy')[()]
tr['AvSigVersion_date'] = tr['AvSigVersion'].map(datedictAS)
te['AvSigVersion_date'] = te['AvSigVersion'].map(datedictAS)

# OS timestamp
datedictOS = np.load('../external/OSVersionTimestamps.npy')[()]
tr['Census_OSVersion_date'] = tr['Census_OSVersion'].map(datedictOS)
te['Census_OSVersion_date'] = te['Census_OSVersion'].map(datedictOS)

# BL timestamp
def convert(x):
    try:
        d = datetime.strptime(x.split('.')[4],'%y%m%d-%H%M')
    except:
        d = np.nan
    return d

tr['OsBuildLab_date'] = tr['OsBuildLab'].map(convert)
te['OsBuildLab_date'] = te['OsBuildLab'].map(convert)


tr['date'] = tr[['AvSigVersion_date', 'Census_OSVersion_date', 'OsBuildLab_date']].max(1).dt.date
te['date'] = te[['AvSigVersion_date', 'Census_OSVersion_date', 'OsBuildLab_date']].max(1).dt.date


trte = pd.concat([tr, te], ignore_index=True)

gc.collect()

def multi(args):
    gc.collect()
    
    key, outpath_tr, outpath_te = args
    
    ct = pd.crosstab(trte['date'], 
                      trte[key], 
                      normalize='index')
    
    melt = pd.melt(ct.reset_index(), 'date')
    melt.columns = ['date', key, f'{key}_ratio']
    
    # shift
    melt[f'lag1_{key}_ratio'] = pd.melt(ct.shift(1).reset_index(), 'date')['value']
    melt[f'lead1_{key}_ratio'] = pd.melt(ct.shift(-1).reset_index(), 'date')['value']
    
    
    keys = ['date', key]
    tr_f = pd.merge(tr[keys], melt, on=keys, how='left')
    te_f = pd.merge(te[keys], melt, on=keys, how='left')
    
    tr_f.drop(keys, axis=1, inplace=True)
    te_f.drop(keys, axis=1, inplace=True)
    
    # output
    tr_f.add_prefix(PREF+'_').to_feather(outpath_tr)
    te_f.add_prefix(PREF+'_').to_feather(outpath_te)
    
    return


os.system(f'rm ../data/tmp_*_{PREF}*')
argss = []
for i,c in enumerate(features):
    argss.append([c, f'../data/tmp_tr_{PREF}_{c}.f', f'../data/tmp_te_{PREF}_{c}.f'])

pool = Pool( cpu_count() )
pool.map(multi, argss)
pool.close()



# train
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_tr_{PREF}*'))], axis=1)
df.to_feather(f'../data/train_{PREF}.f')
del df; gc.collect()

# test
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_te_{PREF}*'))], axis=1)
df.to_feather(f'../data/test_{PREF}.f')

os.system(f'rm ../data/tmp_*_{PREF}*')





utils.end(__file__)

