#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 24 17:41:39 2019

@author: kazuki.onodera

count category


"""

import numpy as np
import pandas as pd
import gc, os
from glob import glob

from multiprocessing import cpu_count, Pool
#from sklearn.preprocessing import LabelEncoder

import utils

PREF = 'f003'


col_cat = ['ProductName',
         'EngineVersion',
         'AppVersion',
         'AvSigVersion',
         'Platform',
         'Processor',
         'OsVer',
         'OsPlatformSubRelease',
         'OsBuildLab',
         'SkuEdition',
         'PuaMode',
         'SmartScreen',
         'Census_MDC2FormFactor',
         'Census_DeviceFamily',
         'Census_ProcessorClass',
         'Census_PrimaryDiskTypeName',
         'Census_ChassisTypeName',
         'Census_PowerPlatformRoleName',
         'Census_InternalBatteryType',
         'Census_OSVersion',
         'Census_OSArchitecture',
         'Census_OSBranch',
         'Census_OSEdition',
         'Census_OSSkuName',
         'Census_OSInstallTypeName',
         'Census_OSWUAutoUpdateOptionsName',
         'Census_GenuineStateName',
         'Census_ActivationChannel',
         'Census_FlightRing']

def frequency_encoding(variable, concat=False, dropna=True):
    """
    https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm
    """
    
    if concat:
        t = pd.concat([tr[variable], te[variable]]).value_counts(dropna=dropna).reset_index()
    else:
        t = tr[variable].value_counts(dropna=dropna).reset_index()
        
    t = t.reset_index()
    t.loc[t[variable] == 1, 'level_0'] = np.nan
    t.set_index('index', inplace=True)
    max_label = t['level_0'].max() + 1
    t.fillna(max_label, inplace=True)
    return t.to_dict()['level_0']

def multi(args):
    
    c, outpath_tr, outpath_te  = args
    
    tr_f = pd.DataFrame(index=tr.index)
    te_f = pd.DataFrame(index=te.index)
    
    # count train
#    freq = tr[c].value_counts()
#    freq = freq.reset_index()
#    freq.columns = [c, 'cnt']
#    rep = dict(zip(freq[c], freq['cnt']))
#    tr_f[c+'_tr'] = tr[c].replace(rep)
#    te_f[c+'_tr'] = te[c].replace(rep)
    di = frequency_encoding(c, False, True)
    tr_f[c+'_tr'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_tr'] = te[c].map(lambda x: di.get(x, np.nan))
    
    # count train and na
#    freq = tr[c].value_counts(dropna=False)
#    freq = freq.reset_index()
#    freq.columns = [c, 'cnt']
#    rep = dict(zip(freq[c], freq['cnt']))
#    tr_f[c+'_tr_na'] = tr[c].replace(rep)
#    te_f[c+'_tr_na'] = te[c].replace(rep)
    di = frequency_encoding(c, False, False)
    tr_f[c+'_tr_na'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_tr_na'] = te[c].map(lambda x: di.get(x, np.nan))
    
    # count train + test
#    freq = trte[c].value_counts()
#    freq = freq.reset_index()
#    freq.columns = [c, 'cnt']
#    rep = dict(zip(freq[c], freq['cnt']))
#    tr_f[c+'_trte'] = tr[c].replace(rep)
#    te_f[c+'_trte'] = te[c].replace(rep)
    di = frequency_encoding(c, True, True)
    tr_f[c+'_trte'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_trte'] = te[c].map(lambda x: di.get(x, np.nan))
    
    # count train + test and na
#    freq = trte[c].value_counts(dropna=False)
#    freq = freq.reset_index()
#    freq.columns = [c, 'cnt']
#    rep = dict(zip(freq[c], freq['cnt']))
#    tr_f[c+'_trte_na'] = tr[c].replace(rep)
#    te_f[c+'_trte_na'] = te[c].replace(rep)
    di = frequency_encoding(c, True, False)
    tr_f[c+'_trte_na'] = tr[c].map(lambda x: di.get(x, np.nan))
    te_f[c+'_trte_na'] = te[c].map(lambda x: di.get(x, np.nan))
    
    # output
    tr_f.add_prefix(PREF+'_').to_pickle(outpath_tr)
    te_f.add_prefix(PREF+'_').to_pickle(outpath_te)
    
    return

# =============================================================================
# main
# =============================================================================
if __name__ == "__main__":
    utils.start(__file__)
    
    tr = pd.read_pickle('../data/train.pkl')[col_cat]
    te = pd.read_pickle('../data/test.pkl')[col_cat]
    
    trte = pd.concat([tr, te], ignore_index=True)
    
    os.system(f'rm ../data/tmp_*_{PREF}*')
    argss = []
    for i,c in enumerate(col_cat):
        argss.append([c, f'../data/tmp_tr_{PREF}_{c}.pkl', f'../data/tmp_te_{PREF}_{c}.pkl'])
    
    pool = Pool( cpu_count() )
    pool.map(multi, argss)
    pool.close()
    
    # train
    df = pd.concat([pd.read_pickle(f) for f in sorted(glob(f'../data/tmp_tr_{PREF}*'))])
    df.to_pickle(f'../data/train_{PREF}.pkl')
    
    # test
    df = pd.concat([pd.read_pickle(f) for f in sorted(glob(f'../data/tmp_te_{PREF}*'))])
    df.to_pickle(f'../data/test_{PREF}.pkl')
    
    os.system(f'rm ../data/tmp_*_{PREF}*')
    
    utils.end(__file__)
