#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Feb  2 21:49:42 2019

@author: Kazuki

OsBuildLab を datetime とみなし、日毎の EngineVersion 等のシェアを計る

"""


import numpy as np
import pandas as pd
import os, gc
from glob import glob
from multiprocessing import cpu_count, Pool
from datetime import datetime

import utils
utils.start(__file__)

PREF = 'f011'


features = ['EngineVersion', 'AppVersion', 'OsBuild', 'Census_OSVersion',
            'IeVerIdentifier', 'Census_OSBranch', 'Census_OSBuildNumber',
            'Census_OSBuildRevision', 'AvSigVersion']


tr = pd.read_feather('../data/train.f')[['OsBuildLab']+features]

te = pd.read_feather('../data/test.f')[['OsBuildLab']+features]

# BL timestamp
def convert(x):
    try:
        d = datetime.strptime(x.split('.')[4],'%y%m%d-%H%M')
    except:
        d = np.nan
    return d

tr['OsBuildLab_date'] = tr['OsBuildLab'].map(convert).dt.date
te['OsBuildLab_date'] = te['OsBuildLab'].map(convert).dt.date


trte = pd.concat([tr, te], ignore_index=True)

gc.collect()

def multi(args):
    gc.collect()
    
    key, outpath_tr, outpath_te = args
    
    tbl = pd.crosstab(trte['OsBuildLab_date'], 
                      trte[key], 
                      normalize='index')
    
    tbl = pd.melt(tbl.reset_index(), 'OsBuildLab_date')
    tbl.columns = ['OsBuildLab_date', key, f'OsBuildLab_{key}_ratio']
    
    keys = ['OsBuildLab_date', key]
    tr_f = pd.merge(tr[keys], tbl, on=keys, how='left')
    te_f = pd.merge(te[keys], tbl, on=keys, how='left')
    
    tr_f.drop(keys, axis=1, inplace=True)
    te_f.drop(keys, axis=1, inplace=True)
    
    # output
    tr_f.add_prefix(PREF+'_').to_feather(outpath_tr)
    te_f.add_prefix(PREF+'_').to_feather(outpath_te)
    
    return


os.system(f'rm ../data/tmp_*_{PREF}*')
argss = []
for i,c in enumerate(features):
    argss.append([c, f'../data/tmp_tr_{PREF}_{c}.f', f'../data/tmp_te_{PREF}_{c}.f'])

pool = Pool( cpu_count() )
pool.map(multi, argss)
pool.close()



# train
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_tr_{PREF}*'))], axis=1)
df.to_feather(f'../data/train_{PREF}.f')
del df; gc.collect()

# test
df = pd.concat([pd.read_feather(f) for f in sorted(glob(f'../data/tmp_te_{PREF}*'))], axis=1)
df.to_feather(f'../data/test_{PREF}.f')

os.system(f'rm ../data/tmp_*_{PREF}*')







utils.end(__file__)

